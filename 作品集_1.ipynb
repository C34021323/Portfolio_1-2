{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVAJ6452kDULN56mwdWBPY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/C34021323/Portfolio_1-2/blob/main/%E4%BD%9C%E5%93%81%E9%9B%86_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **基於SVM跟CNN對人臉辨識的優劣比較**"
      ],
      "metadata": {
        "id": "UKbBy0rLBj_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM測試結果"
      ],
      "metadata": {
        "id": "BZKDnTHhseAR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRREinttAMY0"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 共1560張圖片；每張圖片高為100像素，寬為75像素，彩色\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=50, resize=0.8, color=True)\n",
        "print(lfw_people.images.shape)\n",
        "\n",
        "x=lfw_people.data\n",
        "print(x.shape)\n",
        "\n",
        "y=lfw_people.target\n",
        "names=lfw_people.target_names\n",
        "print(names)\n",
        "\n",
        "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 降維操作(減少特徵值):\n",
        "# svd_solver=指定用哪種方法進行SVD計算；Randomized SVD=以隨機投影為基礎，快速抓取代表性的數據\n",
        "# n_components=將資料降維到某個特徵值數量，並保有重要資訊\n",
        "# whiten=白化處理，使各成分特徵變得獨立\n",
        "pca = PCA(svd_solver='randomized', n_components=100, whiten=True)\n",
        "pca.fit(x,y)\n",
        "x_train_pca = pca.transform(x_train)\n",
        "x_test_pca = pca.transform(x_test)\n",
        "\n",
        "# kernel=核函式，將二維上不可分割的資料映射到三維空間中，用適當的超平面予以分割\n",
        "# rbf=徑向基核(Radial Basis Function)，是一種常用的非線性核函式\n",
        "# C=正則化參數，數字越大，越可避免錯誤分類，但越有機會出現過擬合的情況\n",
        "# gamma=控制SVM的決策邊界；值越大，模型越複雜，越易過擬合；值越小，模型越簡單，越易欠擬合\n",
        "clf = SVC(kernel='rbf', C=100, gamma='auto', probability=True)\n",
        "clf = clf.fit(x_train_pca, y_train)\n",
        "\n",
        "score = clf.score(x_test_pca, y_test)\n",
        "print('測試集準確率:', score)\n",
        "\n",
        "for i in range(15):\n",
        "  print('實際值:', names[y_test[i]], '預測值:', names[clf.predict([x_test_pca[i]])[0]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, clf.predict(x_test_pca))\n",
        "print(cm)\n",
        "\n",
        "# 混淆矩陣視覺化\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "\n",
        "# 在格子標記數字+設定數字顏色\n",
        "thresh = cm.max() / 2  # 閾值\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'), # 將矩陣數字渲染到格子中\n",
        "                 ha='center', va='center',\n",
        "                 color='white' if cm[i, j] > thresh else 'black') # 依條件給定不同顏色的數字\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.xticks(np.arange(cm.shape[1]))\n",
        "plt.yticks(np.arange(cm.shape[0]))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_vt5KzoMNzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN測試結果"
      ],
      "metadata": {
        "id": "F4__qcnHshzf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJaVXejMIx-p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# 轉換函數可根據需求自定義\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "\n",
        "lfw_people=fetch_lfw_people(min_faces_per_person=50, resize=0.8, color=True)\n",
        "\n",
        "x=lfw_people.data # x 是模型的輸入特徵\n",
        "y=lfw_people.target # y 是模型在訓練時用來學習和預測的輸出標籤\n",
        "\n",
        "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "height, width, channels = 100, 75, 3\n",
        "x_train=x_train.reshape(-1, channels, height, width)\n",
        "x_test=x_test.reshape(-1, channels, height, width)\n",
        "\n",
        "x_train=torch.tensor(x_train, dtype=torch.float32)\n",
        "x_test=torch.tensor(x_test, dtype=torch.float32)\n",
        "y_train=torch.tensor(y_train, dtype=torch.long)\n",
        "y_test=torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_dataset=torch.utils.data.TensorDataset(x_train, y_train)\n",
        "test_dataset=torch.utils.data.TensorDataset(x_test, y_test)\n",
        "\n",
        "train_loader=DataLoader(train_dataset, batch_size=96, shuffle=True)\n",
        "test_loader=DataLoader(test_dataset, batch_size=24, shuffle=False)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義CNN模型\n",
        "class ConvNet(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.cn1 = nn.Conv2d(3, 16, 3, 1)\n",
        "        self.cn2 = nn.Conv2d(16, 32, 3, 1)\n",
        "        self.dp1 = nn.Dropout(0.1)\n",
        "        self.dp2 = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(48*35*32, 64)  # fc1的輸入尺寸\n",
        "        self.fc2 = nn.Linear(64, 12)  # 最後的輸出層\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.cn1(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.cn2(x)\n",
        "    x=F.relu(x)\n",
        "\n",
        "# 每 2x2 區域會取最大的值來代表該區域\n",
        "    x=F.max_pool2d(x, 2)\n",
        "# 展平(flatten):將經過卷積層和池化層後的特徵圖轉換為一維向量，從而使其能夠作為FC的輸入，進而分類或迴歸\n",
        "    x=torch.flatten(x, 1)\n",
        "\n",
        "    x=self.fc1(x)\n",
        "    x=self.dp1(x)\n",
        "    x=F.relu(x)\n",
        "\n",
        "    x=self.fc2(x)\n",
        "    x=self.dp2(x)\n",
        "    output=F.log_softmax(x, dim=1)\n",
        "    return output\n",
        "\n",
        "# 建立CNN模型物件\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model=ConvNet().to(device)\n",
        "\n",
        "# 定義損失函數及最佳化方法\n",
        "myloss=nn.NLLLoss() # 配合log_softmax()的損失函數\n",
        "optim=torch.optim.Adadelta(model.parameters(), lr=0.5)\n",
        "\n",
        "batch_size=96\n",
        "\n",
        "# 定義train()副程式，用來訓練模型\n",
        "def train(model, device, train_loader, myloss, optim, epoch): # train_loader=自動將數據分成數個batch，批次載入\n",
        "\n",
        "  model.train()\n",
        "  total_samples = len(train_loader.dataset)  # 總樣本數量\n",
        "\n",
        "# 訓練模型的過程經常是由一個大迴圈(epoch)+一個小迴圈(batch training)組成\n",
        "# 對dataloader中每個batch資料進行迴圈操作；b_i是batch的索引；(X, y)=每個batch中的輸入/ 標籤\n",
        "  for b_i, (X, y) in enumerate(train_loader):\n",
        "    X, y=X.to(device), y.to(device)\n",
        "    pred_prob=model(X) # 實際調用forward方法，執行前向傳播\n",
        "    loss=myloss(pred_prob, y)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    if b_i%1==0:\n",
        "      num1=b_i*len(X)\n",
        "      num2=len(train_loader.dataset)\n",
        "      num3=100*b_i/len(train_loader)\n",
        "      print(f'Train Epoch: {epoch} [{num1}/{num2} ({num3:.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "epochs=3\n",
        "for epoch in range(epochs):\n",
        "  train(model, device, train_loader, myloss, optim, epoch)\n",
        "\n",
        "torch.save(model.state_dict(), 'mnist_cnn.pt') # 儲存模型參數，以字典形式儲存，日後不必重新訓練"
      ],
      "metadata": {
        "id": "15uUe6KlVudL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2=ConvNet()\n",
        "model2.load_state_dict(torch.load('mnist_cnn.pt')) # 引用儲存的模型，繼續訓練\n",
        "model2=model2.to(device)\n",
        "\n",
        "# 定義test()副程式，用來測試模型\n",
        "def test(model, device, test_loader, myloss): # test_loader=自動將數據分成數個batch，批次載入\n",
        "\n",
        "  model.eval()\n",
        "  loss=0\n",
        "  success=0 # 從0開始，逐步累加正確預測次數\n",
        "\n",
        "# 預測階段時，模型的參數（權重和偏差）應該保持固定，不應該被更新\n",
        "  with torch.no_grad():\n",
        "    for X, y in test_loader:\n",
        "      X, y=X.to(device), y.to(device)\n",
        "      pred_prob=model(X)\n",
        "      loss+=myloss(pred_prob, y).item()\n",
        "\n",
        "# 計算模型預測正確次數\n",
        "      pred=pred_prob.argmax(dim=1, keepdim=True) # argmax()可找出最大tensor的index\n",
        "      success+=pred.eq(y.view_as(pred)).sum().item() # eq()可比較tensor是否相等\n",
        "\n",
        "      num1=loss/len(test_loader)\n",
        "      num2=len(test_loader.dataset)\n",
        "      num3=100*success/len(test_loader.dataset)\n",
        "      print('Overall Loss:{:.4f}, overall Accuracy: {}/{}({:.2f}%)'.format(num1, success, num2, num3))\n",
        "\n",
        "test(model2, device, test_loader, myloss)"
      ],
      "metadata": {
        "id": "pyCNB15HI_5M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}